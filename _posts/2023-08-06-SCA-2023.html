---
layout: post
title: "SCA 2023"
---


<!DOCTYPE html>
<html>
    <head>

        <style>

        </style>

    </head>

    <body>
        
        <div>
            <p>This weekend I attended  <a href="https://computeranimation.org/2022/">22nd annual ACM SIGGRAPH/Eurographics Symposium on Computer Animation (SCA 2023)</a> in sunny Los Angeles, California. The conference was held at the UCLA campus.
                This was my second SCA conference - last year I attended the 2022 edition in Durham.
                However, this year I was attending to present my paper <em>NeuroDog: Quadruped Embodiment using Neural Networks</em>. I presented the paper in the <em>Character Synthesis</em> session on day two of the conference. 
                The paper has also been accepted for journal publication in Proceedings of the ACM in Computer Graphics and Interactive Techniques (PACMCGIT) special issue on SCA.
            </p>

            

            <!--more-->

            <img src="/assets/images/SantaMonica.jpg" alt="Santa Monica" style="width:400px;height:300px;"> 

            <p>
                In the paper, we present our novel virtual reality (VR) quadruped embodiment system called <em>NeuroDog</em>. 
                NeuroDog is the first VR quadruped embodiment system to use deep learning to synthesise realistic motion for the
virtual quadruped. The user, viewing themselves as a quadruped from a first-person perspective, is
able to perform different actions in a natural, intuitive and relatively unconstrained manner. The
virtual quadruped mimics their actions, switching gaits as the user moves faster or slower, sitting as
the user sits, or raising its paws as the user raises their legs. The core novelty within NeuroDog is
a novel architecture, built using two neural networks, for the real-time mapping of natural human
motion to realistic quadruped motion. The architecture is designed to preserve the synchrony between the user’s legs and the virtual quadruped’s front legs when performing
tasks such as locomotion or paw-raises.
                We also present new perceptual results regarding virtual animal embodiment. Check out the <a href="https://doegan32.github.io/publications">paper</a> for all the details!
            </p>

            <p>
                It was great to see all the other amazing paper presentations together with some really interesting key-notes!
            </p>
       </div>
       


    </body>    
